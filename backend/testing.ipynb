{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2  # To extract text from PDF files\n",
    "\n",
    "\n",
    "# Function to extract all text from a PDF file\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "    text = ''\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        text += page.extract_text()  # Extract the text from each page\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = extract_text_from_pdf(\"SparkQuest.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SparkQuest\\nProject Team\\nMaheen Shoukat 21I-2719\\nTalha Nadeem 21I-0313\\nSyeda Aiman Azhar 21I-0290\\nSession 2020-2024\\nSupervised by\\nMr. Adil Majeed\\nCo-Supervised by\\nDr. Usman Haider\\nDepartment of Computer Science\\nNational University of Computer and Emerging Sciences\\nIslamabad, Pakistan\\nJune, 2024Contents\\n1 Introduction 11\\n1.1 Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n1.2 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n1.3 Problem Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\\n1.4 Stake Holders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\\n1.5 Comparison with Existing Technology . . . . . . . . . . . . . . . . . . . 22\\n2 Project Description 55\\n2.1 Scope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\n2.2 Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\n2.2.1 Module 1 - Two modes of the Client Web Application . . . . . . . 66\\n2.2.2 Module 2 - Question Answering(QA) in User Mode . . . . . . . . 66\\n2.2.3 Module 3 - Question Answering from User in Evaluation Mode . 66\\n2.2.4 Module 4 - Parental/Guardian Role in Evaluation Mode . . . . . . 77\\n2.2.5 Module 5 - Audio Input and Output . . . . . . . . . . . . . . . . 77\\n2.2.6 Module 6 - Dual language Support . . . . . . . . . . . . . . . . . 77\\n2.2.7 Module 7 - Database . . . . . . . . . . . . . . . . . . . . . . . . 88\\n2.3 Tools and Technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\\n2.4 Work Division . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\\n2.5 TimeLine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1010\\nReferences 1111\\n2List of Figures\\n3List of Tables\\n1.1 Feature Comparison Across Similar Applications . . . . . . . . . . . . . 33\\n2.1 Work distribution table . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\\n2.2 Timeline of the project . . . . . . . . . . . . . . . . . . . . . . . . . . . 1010\\n0Chapter 1\\nIntroduction\\n.\\n1.1 Problem Statement\\nAs education is evolving rapidly, the traditional learning methods are now falling short.\\nMost of the times theses traditional learning methods fail to engage a young learner’s\\nmind, due to which a student loses focus. The primary grade students require an interac-\\ntive and dynamic learning environment to enhance their learning [ 66]. Such platforms not\\nonly captures a students interest but also fulfills the need of diverse learning styles. There\\nare multiple products in the market that can be used to engage a student but they mostly\\ntarget a single aspect of learning and do not fully engage a student. Moreover, there is\\na gap in existing educational tools that offer audio- visual aid and an interactive learning\\nenvironment for the students. The gap is quite notable when it comes to regions like Pak-\\nistan, where not everyone can speak English. Such language barriers affect the learning\\nof a student as they are unable to grasp the concepts fully. A tool that caters to the stu-\\ndent’s bilingual needs and also provides them with an interactive learning environment by\\ncombining different aspects of interactive learning is crucial for the students, especially\\nof Pakistan region. An application like this can bridge the gaps, enhance creativity and\\nengage students into critical thinking[ 77].\\n1.2 Motivation\\nThe need for developing SparkQuest roots from the idea of a platform that provides an\\nencouraging learning space for primary grade students. The web application aims to\\nbring a new landscape of education by incorporating the use of Generative AI and Re-\\n11. Introduction\\ntrieval Augmented Reality (RAG). Such technologies can enhance a student’s learning\\noutcomes by engaging their auditory, visual and cognitive abilities altogether [ 77]. In the\\nregion of Pakistan not many primary grade students have the ability to read or understand\\nEnglish which hinders their learning and becomes a barrier in their education. We want\\nto provide these students with a bilingual platform which has support for English as well\\nas Urdu language. The inspiration behind the project comes from the ability of Artificial\\nIntelligence (AI) to engage and interact with the user to provide a supportive educational\\nexperience for enhanced learning[ 66].\\n1.3 Problem Solution\\nThe solution we propose is SparkQuest, AI powered learning platform for primary grade\\nstudents, is a web application that aims to address the evolving educational needs of a\\nprimary grade student[ 77]. By creating an engaging bilingual web application for students\\nof Pakistan, we want to enhance their learning experience and aim to make learning more\\nfun for them. This app is equipped with several modules which would cater to different\\nlearning styles of each student. Moreover it also aims to break the language barrier by\\nproviding audio support in English and Urdu both. Through the proposed solution based\\non United Nation’s fourth Sustainable Development Goal of Education, we aim to bridge\\nthe gap in education and foster creativity among young minds [ 55].\\n1.4 Stake Holders\\n1. Primary grade students\\n2. Parents, Guardians\\n3. Teachers\\n4. Public/Private Educational Institutions\\n5. Developers\\n6. Designers\\n1.5 Comparison with Existing Technology\\nThe detailed comparison of some similar educational applications is analysed, It is visible\\nfrom the table that many existing apps do not have a combination of all modules that\\nSparkQuest offers. [ 11][22][33][44].\\n21.5 Comparison with Existing Technology\\nTable 1.1: Feature Comparison Across Similar Applications\\nFeatures\\\\App Khan\\nAcademyQuizlet Read\\nTheorySocratic by\\nGoogleSparkQuest\\nQ/A Module from\\nText, PDF - User\\nMode× × × × ✓\\nVQA - User Mode × × × × ✓\\nText to Audio Sup-\\nport× × × × ✓\\nTopic Explanation &\\nQA - Eval mode✓ ✓ ✓ × ✓\\nDual Language Sup-\\nport× × × × ✓\\nSubscription ✓ ✓ × × ×\\n3Chapter 2\\nProject Description\\n2.1 Scope\\nThe scope of SparkQuest lies in developing a user friendly dynamic educational website\\nthat integrates tools like Generative AI and RAG. SparkQuest targets the students of grade\\none to five and it focuses on three major subjects of English, Maths and Science. A core\\nfunctionality of this app is the multi-modal question answering module where student\\ncan ask questions from a document, image or video. Additionally, this feature allows\\nstudent to upload the content they want to ask questions from. Moreover, the web app also\\nprovides the student with text to audio support, aiding the auditory learners. A bilingual\\nsupport for Urdu and English language is also incorporated in the web app. Another\\ncrucial feature is the inclusion of parental/guardian role where the parent/guardian can\\nmonitor their child’s progress.\\nWith SparkQuest, we hope to make education fun for young leaders. The project focuses\\non making the use of AI in the field of education to make it more fun for the primary\\ngrade students. With the advancements in the field of AI we can make education a way of\\nfostering creativity among the students where they can learn in a collaborative environ-\\nment.\\n2.2 Modules\\nSparkQuest, an E-learning web app, is based on a total of seven modules. These modules\\nare divided into two modes, User mode and Evaluation mode. The modules are interlinked\\ncomponents at the back-end that will provide a complete learning experience to a primary\\ngrade student to promote additional self learning.\\n52. Project Description\\n2.2.1 Module 1 - Two modes of the Client Web Application\\nThis module will consist of two modes, User mode and Evaluation mode. The user mode\\nwill be for guided learning of students where they can learn from the material by asking\\nquestions, getting summaries from it or visualizing. The evaluation mode will be a test\\nbased module for the students with add-on features like Parental controls to ensure that\\nstudent learning curve is supervised.\\n1. Student Mode\\n2. Evaluation Mode\\n3. Parental Controls (Refer to Module 5)\\n2.2.2 Module 2 - Question Answering(QA) in User Mode\\nIn the user QA mode, students will make use of various types of media to ask ques-\\ntions and understand ambiguous concepts, helping them understand and describe what is\\nhappening in the content. These different types of media include text, pdf files, images\\nand videos. Here, a user can either upload these media files or choose from an existing\\ndatabase provided in the web application.\\n1. Text-based Question Answering via RAG\\n2. Visual Question Answering from images and videos via RAG\\n2.2.3 Module 3 - Question Answering from User in Evaluation Mode\\nFollowed by the explanations and summaries generated in the user mode (refer to Module\\n3), the student can enter the evaluation mode through the UI where they will be accessed\\nthrough a series of questions of their understanding from generated content(explanation,\\nsummary) of that topic. Moreover, students will also be given the option to directly start\\na test based on their preference of grade, subject and topic. This will help them analyse\\ntheir understanding of a topic and aid in preparing for tests.\\n1. Question generation and its types (Short answers, Fill in the blanks, MCQs etc)\\n2. Question segmentation based on complexity - Subject and Grade\\n3. Recommendation system of questions\\n4. Evaluation of answers\\n5. Timed Module\\n62.2 Modules\\n2.2.4 Module 4 - Parental/Guardian Role in Evaluation Mode\\nThis module introduces a dedicated interface for parents or guardians to monitor the stu-\\ndent’s progress and interactions with the chatbot. The module allows them to view all\\nconversations between the student and the chatbot across Module 2, Module 3, and Mod-\\nule 4. By reviewing these chats, parents or guardians can provide constructive feedback,\\nhelping the student correct any misunderstandings or inaccuracies. This feature acts as\\nan additional safeguard, ensuring that the student is learning accurate information and\\npromoting a collaborative learning environment between the child and their guardians.\\n1. Report generation of complete Chat\\n2. Parent/Guardian’s feedback to the system\\n2.2.5 Module 5 - Audio Input and Output\\nAs primary grade students may not be very fluent with English typing, therefore this\\nmodule will give them an opportunity to provide audio input and receive an audio output.\\nFor example, a student can ask the web app through audio support to produce a summary\\nor a question. The web app will process this audio input and generate text based results,\\nfollowed by a prompt that takes user preference of how they want the results, i.e text only\\nor text along with audio. Users can set this in default options of the application also.\\n1. Audio Input Processing\\n2. Audio Output Processing\\n3. Default settings of Audio Input/Output\\n4. Integration with all other Modules\\n2.2.6 Module 6 - Dual language Support\\nThe geographic audience of the E-learning website is limited to the region of Pakistan,\\nhence the dual language support will incorporate Urdu language. This module will be\\nintegrated with Module 6, where a user will be provided with option to provide an Urdu\\naudio input and receive audio output in Urdu.\\n1. Urdu Speech to Text\\n2. Urdu Text to Speech\\n72. Project Description\\n3. Urdu to English context understanding\\n4. Urdu English Translation\\n2.2.7 Module 7 - Database\\nAn extensive database will be maintained for this website. This will record data of user\\nand parent/guardian including their Grade. Moreover, all questions and answers, sum-\\nmaries and explanations will also be recorded here. This personalised data of students\\nwill be used to generate questions (ref to module 4) and improve the quality of responses\\nover time. The schema will cover the following aspects:\\n1. Student details\\n2. Parent/Guardian details\\n3. Questions generated\\n4. Questions asked by user and their corresponding answers generated\\n5. Generated summaries and explanations\\n2.3 Tools and Technologies\\nProvide a detail of the tools and technologies required for this project.\\n1. Python\\n2. FASTAPIs\\n3. Hugging Face\\n4. Retrieval Augmented Generation (RAG)\\n5. LangChain\\n6. Vector Database\\n7. React\\n8. JavaScript\\n9. Uvicorn\\n10. SQLite\\n82.4 Work Division\\n2.4 Work Division\\nBelow we have mentioned the work distribution table where we have divided the work\\namong three members.\\nTable 2.1: Work distribution table\\nName Registration Responsibility/ Module / Feature\\nMs. Maheen 21I-2719 (Module 2- Feat 1-2) Question Answering in User Mode\\n(Module 3- Feat 1-2, 5) QA from User - Types of questions,\\ngeneration, personalised complexity level and adding a time limit.\\nBasic frontend tasks.\\n(Module 4- Feat 1) Parental/Guardian Role in Evaluation Mode:\\nReport generation of complete Chat and Frontend relating to\\nreport generation.\\n(Module 5- Feat 1-3) Audio Input and Output feature’s Complete\\nfrontend and integration with backend models.\\n(Module 6- Feat 1,3) Dual Language Support : Urdu Speech to Text\\nwith contextual understanding.\\nMr. Talha 21I-0313 (Module 2- Feat 2) Visual Question Answering and its\\nIntegration with Frontend\\n(Module 3- Feat 2-3) QA from User - Personalised complexity\\nlevel and recommendation system based on it.\\n(Module 4- Feat 2) Parental/Guardian Role in Evaluation Mode:\\nParent/Guardian’s feedback to the system.\\n(Module 5- Feat 1-2) Audio Input and Output Processing.\\n(Module 6- Feat 2-3) Dual Language Support : Urdu Text to Speech\\nwith contextual understanding.\\nMs. Aiman 21I-0290 (Module 2- Feat 1-2) Complete Front end for Module 2 and its\\nIntegration with Backend\\n(Module 3- Feat 4) QA from User - Criteria for answer evaluation\\nalong with Frontend integration of this Module.\\n(Module 4- Feat 2) Parental/Guardian Role in Evaluation Mode:\\nParent/Guardian’s feedback to the system. Main focus on frontend\\nintegration.\\n(Module 5- Feat 3) Adding Audio Input and Output feature to\\ndefault settings and model optimization.\\n(Module 6- Feat 3-4) Dual Language Support : Language translation\\nwith contextual understanding.\\n92. Project Description\\n2.5 TimeLine\\nThe timeline of the final year project that is to be followed during the given time of project\\nis mentioned below.\\nTable 2.2: Timeline of the project\\nIteration# Time frame Tasks/Modules\\n01 Sept-Oct RAG based Question Answering in User Mode\\n02 Nov-Dec Parental/Guardian Role in Evaluation Mode, Topic Explanation and\\nSummarization in User Mode\\n03 Jan-Feb Topic Question Answering from User in Evaluation Mode,\\nText to Audio Feature, Dual Language Support\\n04 Mar-Apr Report generation, Thorough Front-End Integration and Testing\\n10Bibliography\\n[1] Digital Flashcards & Revision Cards for Students.\\n[2] Get unstuck. Learn better. | Socratic.\\n[3] Khan Academy | Free Online Courses, Lessons & Practice.\\n[4] ReadTheory | Reading Comprehension Exercises.\\n[5] THE 17 GOALS | Sustainable Development.\\n[6] Ika Agustina, Lailan Aprina Siregar, Desy Liliani Husain, Asfahani Asfahani, and\\nPahmi Pahmi. Utilization of Digital Technology in Children’s Education to Enhance\\nCreative and Interactive Learning. At-Tarbawi: Jurnal Pendidikan, Sosial dan Kebu-\\ndayaan , 10(2):276–283, November 2023. Number: 2.\\n[7] Hazem Alrakhawi, Nurullizam Jamiat, and Samy Abu-Naser. INTELLIGENT TU-\\nTORING SYSTEMS IN EDUCATION: A SYSTEMATIC REVIEW OF USAGE,\\nTOOLS, EFFECTS AND EV ALUATION. Journal of Theoretical and Applied Infor-\\nmation Technology , 101:1205–1226, February 2023.\\n11'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/philschmid/bart-large-cnn-samsum\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Eiffel Tower is 324 metres tall and the second tallest free-standing structure in France after the Millau Viaduct. It was the first structure to reach a height of 300 metres and it is now taller than the Chrysler Building by 5.2 metres.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/process_pdf_query/\")\n",
    "async def upload_pdf(query_text: str = Form(...), pdf_file_name: str = Form(...)):\n",
    "    pdf_file_path = os.path.join(\"D:\\\\FYP\\\\backend\", pdf_file_name)  \n",
    "    pdf_text = extract_text_from_pdf(pdf_file_path)\n",
    "    sentences = sent_tokenize(pdf_text)\n",
    "    sentence_chunks = create_sentence_chunks(sentences, chunk_size, chunk_overlap)\n",
    "    documents = docer(sentence_chunks)\n",
    "    document_contents = [doc.page_content for doc in documents]\n",
    "    x = extract_embeddings(document_contents)\n",
    "    index = insert_to_vdb(documents, embeddings)\n",
    "    final_in = get_new_input(query_text, index, embeddings)\n",
    "    outer = get_new_output(final_in)\n",
    "    play_audio(outer)\n",
    "    return {\"response\": outer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/microsoft/speecht5_tts\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.content\n",
    "\n",
    "audio_bytes = query({\n",
    "\t\"inputs\": \"Chatbot explains to User what a network is and how it works. The current weather in New York is 75 degrees with a sunny day. Embeddings are used to convert text into numerical values and to represent them into sentences and sentences. The network processes data and passes it through connected connected layers.\",\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,SW50ZXJuYWwgU2VydmVyIEVycm9y\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can access the audio with IPython.display for example\n",
    "from IPython.display import Audio\n",
    "Audio(audio_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muhammad Sharjeel Resume\n",
      "dksjhfjkdhf\n",
      "asdljsalkdja\n",
      "\n",
      "dalskdjlsakdj\n"
     ]
    }
   ],
   "source": [
    "def read_first_lines(file_path, num_lines=5):\n",
    "    \"\"\"\n",
    "    Open the file at file_path and print out the first num_lines lines.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            for _ in range(num_lines):\n",
    "                line = f.readline()\n",
    "                if not line:\n",
    "                    break\n",
    "                print(line.rstrip())\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Change this to the name of the file you want to read\n",
    "    filename = \"hi.txt\"\n",
    "    path = f\"/Users/sharjeel/Desktop/UNI Work/FYP-Kinetikids-main/FYP/backend/hi.txt\"\n",
    "    read_first_lines(path, num_lines=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
